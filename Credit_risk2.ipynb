{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0826e9-b5a6-4802-8150-ebf804cfa3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Logistic Regression '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Logistic Regression \"\"\"\n",
    "\n",
    "# probabilites of default come from column data (features)\n",
    "# based on classification models --> default or no-default\n",
    "# log reg and decision tree are most common models\n",
    "# log reg only produces output between 0 and 1\n",
    "\n",
    "# prob(loan_status=1) = 1/(1=e^-gamma) log reg function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c219f6-df27-43c6-b922-d90299f5076c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Once you create the training and test sets, .fit(x,y) must use the training data (X_train, y_train) '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Sci-kit learn \"\"\"\n",
    "\n",
    "# from sklearn.linear.model import LogisticRegression\n",
    "# the function is 'name' = LogisticRegression(solver = 'lbfgs') --> argument value is the default value\n",
    "\n",
    "# .fit(training_columns, np.ravel(training_labels)) --> method used to train the model --> np.ravel makes labels a 1D array instead of DF\n",
    "# training columsn = all columns except loan_status\n",
    "\n",
    "# ex) x = cr_loan.drop('loan_status', axis =1)\n",
    "#     y = cr_loan[['loan_status']]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 123)\n",
    "# test_size = % of data for test set\n",
    "\n",
    "# .get_params() --> provides output of model parameters\n",
    "# .intercept_ --> provides intercept of the model\n",
    "\n",
    "''' Once you create the training and test sets, .fit(x,y) must use the training data (X_train, y_train) '''\n",
    "# .coef_ provides the coefficients of the model. the more positive, the more predictive it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98d8873-1a48-444e-8662-d863d6c645b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' One-hot encoding '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' One-hot encoding '''\n",
    "\n",
    "# in python, we cannot use string values to train a ML model --> R can do this\n",
    "# we assign a number to a string value --> 0 or 1 usually\n",
    "# we use get_dummies() in pandas\n",
    "\n",
    "# ex) cred_num = cr_loan.select_dtypes(exclude=['object']) --> separates numeric columns\n",
    "#     cred_cat = cr_loan.select_dtypes(include=['object']) --> separates non-numeric columns\n",
    "#     cred_cat_onehot = pd.get_dummies(cred_cat) --> one-hot encode non-numeric\n",
    "#     cr_loan = pd.concat([cred_num, cred_cat_onehot], axis=1) --> union numeric and one-hot columns\n",
    "\n",
    "# train the model \n",
    "# clf_logistic.fit(X_train, np.ravel(y_train)) --> trains the model\n",
    "# clf_logistic.predict_proba(X_test) --> predicts based on training\n",
    "\n",
    "# [:,_] --> all rows in column _\n",
    "# [:,1][0:5] --> all rows in column 1, then sub index for rows 0-5 from column 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb8f81c-f09c-4365-bddd-451d6081cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the logistic regression model on the training data\n",
    "#  clf_logistic =LogisticRegression(solver='lbfgs').fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Create predictions of probability for loan status using test data\n",
    "#  preds = clf_logistic.predict_proba(X_test)\n",
    "\n",
    "# Create dataframes of first five predictions, and first five true labels\n",
    "#  preds_df = pd.DataFrame(preds[:,1][0:5], columns = ['prob_default'])\n",
    "#  true_df = y_test.head()\n",
    "\n",
    "# Concatenate and print the two data frames for comparison\n",
    "#  print(pd.concat([true_df.reset_index(drop = True), preds_df], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c010bd2-0225-40df-a26f-9618e8f135ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Model Performance '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Model Performance '''\n",
    "\n",
    "# a first approach to determining performance is calculating accuracy: # correct predictions/# of predictions\n",
    "# can use the DF.score(_, _) method --> X_test, y_test inputs\n",
    "\n",
    "# ROC curves can be used to assess as well --> Receiver operating characteristic curve\n",
    "# True positive rate (sensitivity) vs false positive rate (fall-out)\n",
    "# ex) fallout, sensitivity, thresholds = roc_curve(y_test, prob_default)\n",
    "#     plt.plot(fallout, sensitivity, color = 'darkorange')\n",
    "# for an ROC curve, we want the curve to be as far left from the 45 degree line --> better predictor (more lift = better predictor)\n",
    "\n",
    "# Thresholds need to be established\n",
    "\n",
    "# ex) preds = clf_logistic.predict_proba(X_test)\n",
    "#     preds_df = pd.DataFrame(preds[:,1], columns = ['prob_default'])\n",
    "#     preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.5 else 0) --> lambda function is temporary to define threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1e78b4-28cf-4909-851f-4c869cf2b835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classification report'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''classification report'''\n",
    "\n",
    "# from sklearn.metrics import classification_report\n",
    "# classification_report(y_test, preds_df['loan_status'], target_names=target_names)\n",
    "\n",
    "# example) \n",
    "\n",
    "# Create a dataframe for the probabilities of default\n",
    "#  preds_df = pd.DataFrame(preds[:,1], columns = ['prob_default'])\n",
    "\n",
    "# Reassign loan status based on the threshold\n",
    "#  preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Print the row counts for each loan status\n",
    "#  print(preds_df['loan_status'].value_counts())\n",
    "\n",
    "# Print the classification report\n",
    "#  target_names = ['Non-Default', 'Default']\n",
    "#  print(classification_report(y_test, preds_df['loan_status'], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283256e4-2566-4422-a3b7-d51c313dcf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example)\n",
    "\n",
    "# Create predictions and store them in a variable\n",
    "#  preds = clf_logistic.predict_proba(X_test)\n",
    "\n",
    "# Print the accuracy score the model\n",
    "#  print(clf_logistic.score(X_test, y_test))\n",
    "\n",
    "# Plot the ROC curve of the probabilities of default\n",
    "#  prob_default = preds[:, 1]\n",
    "#  fallout, sensitivity, thresholds = roc_curve(y_test, prob_default)\n",
    "#  plt.plot(fallout, sensitivity, color = 'darkorange')\n",
    "#  plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "#  plt.show()\n",
    "\n",
    "# Compute the AUC and store it in a variable\n",
    "#  auc = roc_auc_score(y_test, prob_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1778f135-147f-40fc-bbc4-ecdc75397d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Confusion matrix '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Confusion matrix '''\n",
    "\n",
    "# shows the number of correct and incorrect predictions for each loan status --> true negative, false positive, etc.\n",
    "# TP, FN, FP, TN\n",
    "# Default recall (sensitivity) --> proportion of true defaults predicted --> TP / (TP + FN)\n",
    "\n",
    "# example)\n",
    "# Reassign the values of loan status based on the new threshold\n",
    "#  preds_df['loan_status'] = preds_df['prob_default'].apply(lambda x: 1 if x > 0.4 else 0)\n",
    "\n",
    "# Store the number of loan defaults from the prediction data\n",
    "#  num_defaults = preds_df['loan_status'].value_counts()[1]\n",
    "\n",
    "# Store the default recall from the classification report\n",
    "#  default_recall = precision_recall_fscore_support(y_test,preds_df['loan_status'])[1][1]\n",
    "\n",
    "# Calculate the estimated impact of the new default recall rate\n",
    "#  print(avg_loan_amnt * num_defaults * (1 - default_recall))\n",
    "\n",
    "# print(confusion_matrix(y_test,gbt_preds))\n",
    "# print(confusion_matrix(y_test,gbt2_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd3c89-381b-4aa3-a39d-181def420861",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' threshold selection ''' \n",
    "\n",
    "#plt.plot(thresh,def_recalls)\n",
    "#plt.plot(thresh,nondef_recalls)\n",
    "#plt.plot(thresh,accs)\n",
    "#plt.xlabel(\"Probability Threshold\")\n",
    "#plt.xticks(ticks)\n",
    "#plt.legend([\"Default Recall\",\"Non-default Recall\",\"Model Accuracy\"])\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
