{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f279f69-110e-4796-9070-1e85cfd6c8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' XgBoost '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' XgBoost '''\n",
    "\n",
    "# clf_gbt = xgb.XGBClassifier() --> create gbt model\n",
    "# clf_gbt.fit(X_train, np.ravel(y_train)) --> train boosted tree\n",
    "# use .predict_proba(X_test) and .predict(X_test) used here again\n",
    "\n",
    "# model has hyperparameters that can adjusted to improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb2432ae-6fb6-4bf3-ad5e-ccbed3dfaa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example)\n",
    "\n",
    "# Train a model\n",
    "#  import xgboost as xgb\n",
    "#  clf_gbt = xgb.XGBClassifier().fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Predict with a model\n",
    "#  gbt_preds = clf_gbt.predict_proba(X_test)\n",
    "\n",
    "# Create dataframes of first five predictions, and first five true labels\n",
    "#  preds_df = pd.DataFrame(gbt_preds[:,1][0:5], columns = ['prob_default'])\n",
    "#  true_df = y_test.head()\n",
    "\n",
    "# Concatenate and print the two data frames for comparison\n",
    "#  print(pd.concat([true_df.reset_index(drop = True), preds_df], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2ca332-3a39-4a37-be59-66913afde9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Expected Loss '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Expected Loss ''' \n",
    "\n",
    "# Print the first five rows of the portfolio data frame\n",
    "#  print(portfolio.head())\n",
    "\n",
    "# Create expected loss columns for each model using the formula\n",
    "#  portfolio['gbt_expected_loss'] = portfolio['gbt_prob_default'] * portfolio['lgd'] * portfolio['loan_amnt']\n",
    "#  portfolio['lr_expected_loss'] = portfolio['lr_prob_default'] * portfolio['lgd'] * portfolio['loan_amnt']\n",
    "\n",
    "# Print the sum of the expected loss for lr\n",
    "#  print('LR expected loss: ', np.sum(portfolio['lr_expected_loss']))\n",
    "\n",
    "# Print the sum of the expected loss for gbt\n",
    "#  print('GBT expected loss: ', np.sum(portfolio['gbt_expected_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb39849e-90be-46c0-b9fd-4093e7c02bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for loan status\n",
    "#  gbt_preds = clf_gbt.predict(X_test)\n",
    "\n",
    "# Check the values created by the predict method\n",
    "#  print(gbt_preds)\n",
    "\n",
    "# Print the classification report of the model\n",
    "#  target_names = ['Non-Default', 'Default']\n",
    "#  print(classification_report(y_test, gbt_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e1b2ea-e057-4531-8a99-a093e7ab0d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' model default recall is fraction of instances which are correctly labeled positive'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Choosing specific columns for predictions '''\n",
    "\n",
    "# df = cr_loan_prep[['loan_int_rate','person_emp_length']] selects specific columns\n",
    "# df = cr_loan_prep.drop('loan_status',axis = 1) selects all except the dropped\n",
    "\n",
    "# each column's importance is measured differently:\n",
    "# - logistic regression: column coefficients\n",
    "# - GBT: we assess the weight of each feature\n",
    "\n",
    "# .get_booster() and .get_score(importance_type='weight') methods\n",
    "# returns a dictionary with features and their scores\n",
    "\n",
    "# we can plot column importances ('frequency')\n",
    "# .plot_importance(clf_gbt, importance_type='weight')\n",
    "''' model default recall is fraction of instances which are correctly labeled positive'''\n",
    "\n",
    "# accuracy and recall of the model are assessed using the F1 score --> F1 = 2* (precision*recall)/(precision + recall)\n",
    "# already included in classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9efc1b-73dd-42c4-93fc-1027b8d8e640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Cross validation '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Cross validation '''\n",
    "\n",
    "# is the process that is used to train and test the model in a way that simulates using on new data.\n",
    "# DMatrix is used to segment the data into different pieces \n",
    "# Early stopping tells cross validation to stop after a scoring metric has not improved after a number of iterations.\n",
    "\n",
    "# cross validation takes training data and processes parts (folds) and tests against unused part. Final tesing is on actual test set (new data).\n",
    "\n",
    "# n_folds = number of folds to run\n",
    "# early_stop = number of iterations to run\n",
    "# params = { specific params for cross val} --> objective, binary:logistic, seed:99, eval_metric:auc --> should be created as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825c6b23-a58c-403f-aa82-53655efe9b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructure data to train for XGboost\n",
    "\n",
    "# DTrain = xgb.DMatrix(X_train, label = y_train)\n",
    "# xgb.cv(params, Dtrain, num_boost_round = 5, nfold=n_folds, early_stopping_rounds = early_stop) --> generates test and Train data auc scores\n",
    "\n",
    "# cross_val_score() --> function that does cross val, and scoring all in one\n",
    "# from sklearn.model_seleciton import cross_val_score\n",
    "# xg = xgb.XGBClassifier(learning_rate = 0.4, max_depth = 10)\n",
    "# cross_val_score(gbt, X_train, y_train, cv=5) --> here cv = Number of folds if input is integer\n",
    "\n",
    "# too much cross val can cause the model to be overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b33e723-5ebc-42a2-a01a-6acf963deeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' example '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' example ''' \n",
    "\n",
    "# Create a gradient boosted tree model using two hyperparameters\n",
    "#  gbt = xgb.XGBClassifier(learning_rate = 0.1, max_depth = 7)\n",
    "\n",
    "# Calculate the cross validation scores for 4 folds\n",
    "#  cv_scores = cross_val_score(gbt, X_train, np.ravel(y_train), cv = 4)\n",
    "\n",
    "# Print the cross validation scores\n",
    "#  print(cv_scores)\n",
    "\n",
    "# Print the average accuracy and standard deviation of the scores\n",
    "#  print(\"Average accuracy: %0.2f (+/- %0.2f)\" % (np.mean(cv_scores),\n",
    "                                              # np.std(cv_scores) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca63746-7c9a-43f7-9a1f-4cb981c67c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Class imbalance '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Class imbalance ''' \n",
    "\n",
    "# create two new sets based on actual loan_status\n",
    "\n",
    "#  X_y_train = pd. concat([X_train.reset_index(drop-True),\n",
    "#                          y_train.reset_index(drop=True)], axis = 1) --> concats the training sets\n",
    "\n",
    "# count_nondefault, count_default = X_y_train['loan_status'].value_counts() --> gets counts of both loan status\n",
    "\n",
    "# nondefaults = X_y_train[X_y_train['loan_status'] == 0] --> separate nondefaults from defaults\n",
    "# defaults = X_y_train[X_y_train['loan_status'] == 1]\n",
    "\n",
    "# nondefaults_under = nondefaults.sample(count_default)  --> undersamples the non-defaults \n",
    "# X_y_train_under = pd.concat([nondefaults_under.reset_index(drop=True), --> concats the undersampled non-defaults with the defaults\n",
    "#                               defaults.rest_index(drop=True), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fffc1c-2a9a-470f-8de9-98718e4da30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data sets for defaults and non-defaults\n",
    "#  nondefaults = X_y_train[X_y_train['loan_status'] == 0]\n",
    "#  defaults = X_y_train[X_y_train['loan_status'] == 1]\n",
    "\n",
    "# Undersample the non-defaults\n",
    "#  nondefaults_under = nondefaults.sample(count_default)\n",
    "\n",
    "# Concatenate the undersampled nondefaults with defaults\n",
    "#  X_y_train_under = pd.concat([nondefaults_under.reset_index(drop = True),\n",
    "#                               defaults.reset_index(drop = True)], axis = 0)\n",
    "\n",
    "# Print the value counts for loan status\n",
    "#  print(X_y_train_under['loan_status'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
